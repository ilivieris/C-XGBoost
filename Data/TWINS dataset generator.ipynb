{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert Data\n",
    "\n",
    "Useful notebook to visualize and convert data to npz format for general testing\n",
    "\n",
    "Need to figure out how this was simulated in the CEVAE paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Random generators were initialized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Random generators initialization\n",
    "import random\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "print('[INFO] Random generators were initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Raw_Data/TWINS/twin_pairs_X_3years_samesex.csv')\n",
    "ys = pd.read_csv('./Raw_Data/TWINS/twin_pairs_Y_3years_samesex.csv').drop(['Unnamed: 0'], axis=1)\n",
    "weight = pd.read_csv('./Raw_Data/TWINS/twin_pairs_T_3years_samesex.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "df = df[ (weight['dbirwt_0'] >= 2000) & (weight['dbirwt_1'] >= 2000) ]\n",
    "ys = ys[ (weight['dbirwt_0'] >= 2000) & (weight['dbirwt_1'] >= 2000) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc = open('./Raw_Data/TWINS/covar_desc.txt', 'r').read()\n",
    "desc = eval(desc)\n",
    "\n",
    "types = open('./Raw_Data/TWINS/covar_type.txt', 'r').read()\n",
    "types = eval(types)\n",
    "\n",
    "types['gestat10'] = 'ord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bord'] = (df['bord_0'] < df['bord_1']).astype(int)\n",
    "to_remove = ['Unnamed: 0', 'Unnamed: 0.1', 'infant_id_0', 'infant_id_1',\n",
    "             'brstate', 'stoccfipb', 'mplbir', 'bord_0', 'bord_1']\n",
    "df = df.drop(to_remove, axis=1)\n",
    "\n",
    "for var in to_remove + ['gestat10']:\n",
    "    if var in types:\n",
    "        types.pop(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_vars = {}\n",
    "for key, value in types.items():\n",
    "    group_vars[value] = group_vars.get(value, []) + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = ys.loc[ df.dropna().index ]\n",
    "df = df.loc[ df.dropna().index ]\n",
    "\n",
    "# missing = df.isna().mean(axis=0) > 0.2\n",
    "\n",
    "# max_values = (df.max(axis=0) + 1)[missing]\n",
    "# # print (max_values.shape)\n",
    "\n",
    "# mode_values = df.mode(axis=0).iloc[0][np.logical_not(missing)]\n",
    "# # print (mode_values.shape)\n",
    "\n",
    "\n",
    "# new_category = missing.index[missing]\n",
    "# mode_category = missing.index[np.logical_not(missing)]\n",
    "\n",
    "# print (\"These columns are imputed using max_val + 1\")\n",
    "# print (new_category)\n",
    "\n",
    "# print (\"These columns are imputed using mode\")\n",
    "# print (mode_category)\n",
    "\n",
    "# df[new_category] = df[new_category].fillna(max_values, axis=0)\n",
    "# df[mode_category] = df[mode_category].fillna(mode_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23905, 146)\n",
      "This is not the same as CEVAE but the closest we could get to the author's description\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=group_vars['cat'])\n",
    "print (df.shape)\n",
    "print (\"This is not the same as CEVAE but the closest we could get to the author's description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = df['gestat10'].values.reshape(-1,1)\n",
    "x = df.drop(['gestat10'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "    \n",
    "w0 = 0.1  * np.random.randn(x.shape[1], n) \n",
    "wh = 5 + 0.1 * np.random.randn(1, n)\n",
    "probs = expit(x @ w0 + (z / 10 - 0.1) @ wh)\n",
    "t = np.random.binomial(1, probs)\n",
    "\n",
    "ys = ys.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "noises = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "problem_id = 0\n",
    "for noise in noises:\n",
    "    print (f\"Noise: {100*noise:.0f}%\")\n",
    "    prox = pd.get_dummies(df['gestat10']).values[:, :, np.newaxis]\n",
    "    prox = np.repeat(prox, 3, 1)\n",
    "    prox = np.repeat(prox, n, 2).astype(bool)\n",
    "    flip = (np.random.uniform(size=prox.shape) > (1-noise))\n",
    "    proxies = np.logical_xor(prox, flip).astype(int)\n",
    "\n",
    "    x_repeat = np.repeat(x[:, :, np.newaxis], n, 2)\n",
    "    features = np.concatenate([x_repeat, proxies], axis=1)\n",
    "    \n",
    "    path = \"../Data/Twins\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    count = features.shape[0]\n",
    "    size = int(0.75 * count)\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        temp_x = features[:,:,i]\n",
    "        temp_t = t[:,i].astype(int)\n",
    "        temp_yf = ys[np.arange(ys.shape[0]), temp_t]\n",
    "        temp_ycf = ys[np.arange(ys.shape[0]), 1-temp_t]\n",
    "        temp_mu0 = ys[:, 0]\n",
    "        temp_mu1 = ys[:, 1]\n",
    "        \n",
    "        x_train, x_test, t_train, t_test, yf_train, yf_test, \\\n",
    "           ycf_train, ycf_test, mu0_train, mu0_test, mu1_train, mu1_test, \\\n",
    "            = train_test_split(temp_x, temp_t, temp_yf, temp_ycf, temp_mu0, temp_mu1, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "        np.savez(path + f'/train{problem_id}.npz', x=x_train, t=t_train, yf=yf_train, ycf=ycf_train, mu1=mu1_train, mu0=mu0_train)\n",
    "        np.savez(path + f'/test{problem_id}.npz', x=x_test, t=t_test, yf=yf_test, ycf=ycf_test, mu1=mu1_test, mu0=mu0_test)\n",
    "\n",
    "        # Update counter\n",
    "        problem_id += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
