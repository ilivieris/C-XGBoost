{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All libraries were imported\n",
      "[INFO] Random generators were initialized\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basic libraries\n",
    "import random\n",
    "import time\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# Sklearn library\n",
    "from sklearn.preprocessing   import StandardScaler, RobustScaler\n",
    "# User libraries\n",
    "from utils.data_loading import Synthetic_dataset, TWINS_dataset, IHDP_dataset, ACIC_dataset\n",
    "from utils.metrics      import PEHE, ATE\n",
    "print('[INFO] All libraries were imported')\n",
    "\n",
    "\n",
    "\n",
    "# Random generators initialization\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "print('[INFO] Random generators were initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of cases:  36\n"
     ]
    }
   ],
   "source": [
    "problem = \"ACIC\" # {\"IHDP\", \"Synthetic\", \"TWINS\", \"ACIC\"}\n",
    "path = \"Data/ACIC/\" # {\"Data/Synthetic/\", \"Data/IHDP/\", \"Data/TWINS/\", \"Data/ACIC/\"}\n",
    "filename = f\"./Results/{problem}_XGBoost.csv\"\n",
    "\n",
    "\n",
    "if \"Synthetic\" in problem:\n",
    "    DataLoader = Synthetic_dataset(path=path)\n",
    "elif \"IHDP\" in problem:\n",
    "    DataLoader = IHDP_dataset(path=path)\n",
    "elif \"TWINS\" in problem:\n",
    "    DataLoader = TWINS_dataset(path=path)\n",
    "elif \"ACIC\" in problem:\n",
    "    DataLoader = ACIC_dataset(path=path, train_size=0.8, random_state=1983)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  0\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:2.79715\tvalidation_1-rmse:2.77164\n",
      "[50]\tvalidation_0-rmse:2.79718\tvalidation_1-rmse:2.77167\n",
      "[100]\tvalidation_0-rmse:2.79720\tvalidation_1-rmse:2.77170\n",
      "[150]\tvalidation_0-rmse:2.79723\tvalidation_1-rmse:2.77174\n",
      "[199]\tvalidation_0-rmse:2.79726\tvalidation_1-rmse:2.77177\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.57 seconds\n",
      "\n",
      "\n",
      "Simulation:  1\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:48.17078\tvalidation_1-rmse:48.43190\n",
      "[50]\tvalidation_0-rmse:48.17030\tvalidation_1-rmse:48.43142\n",
      "[100]\tvalidation_0-rmse:48.16983\tvalidation_1-rmse:48.43095\n",
      "[150]\tvalidation_0-rmse:48.16935\tvalidation_1-rmse:48.43048\n",
      "[199]\tvalidation_0-rmse:48.16888\tvalidation_1-rmse:48.43002\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.52 seconds\n",
      "\n",
      "\n",
      "Simulation:  2\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:158.74395\tvalidation_1-rmse:156.11021\n",
      "[50]\tvalidation_0-rmse:158.74223\tvalidation_1-rmse:156.10864\n",
      "[100]\tvalidation_0-rmse:158.74051\tvalidation_1-rmse:156.10708\n",
      "[150]\tvalidation_0-rmse:158.73880\tvalidation_1-rmse:156.10552\n",
      "[199]\tvalidation_0-rmse:158.73713\tvalidation_1-rmse:156.10400\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.98 seconds\n",
      "\n",
      "\n",
      "Simulation:  3\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:62.69763\tvalidation_1-rmse:60.53705\n",
      "[50]\tvalidation_0-rmse:62.61753\tvalidation_1-rmse:60.46047\n",
      "[100]\tvalidation_0-rmse:62.53774\tvalidation_1-rmse:60.38420\n",
      "[150]\tvalidation_0-rmse:62.45829\tvalidation_1-rmse:60.30824\n",
      "[199]\tvalidation_0-rmse:62.38073\tvalidation_1-rmse:60.23410\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.00 seconds\n",
      "\n",
      "\n",
      "Simulation:  4\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:191.21170\tvalidation_1-rmse:212.67856\n",
      "[50]\tvalidation_0-rmse:191.02890\tvalidation_1-rmse:212.47508\n",
      "[100]\tvalidation_0-rmse:190.84675\tvalidation_1-rmse:212.27230\n",
      "[150]\tvalidation_0-rmse:190.66522\tvalidation_1-rmse:212.07023\n",
      "[199]\tvalidation_0-rmse:190.48793\tvalidation_1-rmse:211.87287\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.83 seconds\n",
      "\n",
      "\n",
      "Simulation:  5\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:35.91835\tvalidation_1-rmse:36.55529\n",
      "[50]\tvalidation_0-rmse:35.91551\tvalidation_1-rmse:36.55232\n",
      "[100]\tvalidation_0-rmse:35.91268\tvalidation_1-rmse:36.54936\n",
      "[150]\tvalidation_0-rmse:35.90987\tvalidation_1-rmse:36.54640\n",
      "[199]\tvalidation_0-rmse:35.90711\tvalidation_1-rmse:36.54352\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.44 seconds\n",
      "\n",
      "\n",
      "Simulation:  6\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:46.75887\tvalidation_1-rmse:46.25929\n",
      "[50]\tvalidation_0-rmse:46.75904\tvalidation_1-rmse:46.25950\n",
      "[100]\tvalidation_0-rmse:46.75922\tvalidation_1-rmse:46.25972\n",
      "[150]\tvalidation_0-rmse:46.75940\tvalidation_1-rmse:46.25993\n",
      "[199]\tvalidation_0-rmse:46.75958\tvalidation_1-rmse:46.26014\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.07 seconds\n",
      "\n",
      "\n",
      "Simulation:  7\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:39.00730\tvalidation_1-rmse:38.92533\n",
      "[50]\tvalidation_0-rmse:39.00734\tvalidation_1-rmse:38.92538\n",
      "[100]\tvalidation_0-rmse:39.00739\tvalidation_1-rmse:38.92543\n",
      "[150]\tvalidation_0-rmse:39.00743\tvalidation_1-rmse:38.92548\n",
      "[199]\tvalidation_0-rmse:39.00747\tvalidation_1-rmse:38.92553\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.84 seconds\n",
      "\n",
      "\n",
      "Simulation:  8\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:171.45396\tvalidation_1-rmse:171.25505\n",
      "[50]\tvalidation_0-rmse:171.45392\tvalidation_1-rmse:171.25506\n",
      "[100]\tvalidation_0-rmse:171.45388\tvalidation_1-rmse:171.25508\n",
      "[150]\tvalidation_0-rmse:171.45384\tvalidation_1-rmse:171.25509\n",
      "[199]\tvalidation_0-rmse:171.45381\tvalidation_1-rmse:171.25511\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.35 seconds\n",
      "\n",
      "\n",
      "Simulation:  9\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:2423.80002\tvalidation_1-rmse:84.59293\n",
      "[50]\tvalidation_0-rmse:2423.75829\tvalidation_1-rmse:84.59272\n",
      "[100]\tvalidation_0-rmse:2423.71661\tvalidation_1-rmse:84.59252\n",
      "[150]\tvalidation_0-rmse:2423.67494\tvalidation_1-rmse:84.59231\n",
      "[199]\tvalidation_0-rmse:2423.63421\tvalidation_1-rmse:84.59210\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.57 seconds\n",
      "\n",
      "\n",
      "Simulation:  10\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:65.86694\tvalidation_1-rmse:65.89557\n",
      "[50]\tvalidation_0-rmse:65.86713\tvalidation_1-rmse:65.89575\n",
      "[100]\tvalidation_0-rmse:65.86731\tvalidation_1-rmse:65.89593\n",
      "[150]\tvalidation_0-rmse:65.86750\tvalidation_1-rmse:65.89611\n",
      "[199]\tvalidation_0-rmse:65.86768\tvalidation_1-rmse:65.89629\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.41 seconds\n",
      "\n",
      "\n",
      "Simulation:  11\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:349.96740\tvalidation_1-rmse:382.87528\n",
      "[50]\tvalidation_0-rmse:349.96225\tvalidation_1-rmse:382.86952\n",
      "[100]\tvalidation_0-rmse:349.95711\tvalidation_1-rmse:382.86377\n",
      "[150]\tvalidation_0-rmse:349.95199\tvalidation_1-rmse:382.85803\n",
      "[199]\tvalidation_0-rmse:349.94698\tvalidation_1-rmse:382.85243\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.76 seconds\n",
      "\n",
      "\n",
      "Simulation:  12\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:119.17228\tvalidation_1-rmse:119.00238\n",
      "[50]\tvalidation_0-rmse:119.17208\tvalidation_1-rmse:119.00218\n",
      "[100]\tvalidation_0-rmse:119.17188\tvalidation_1-rmse:119.00198\n",
      "[150]\tvalidation_0-rmse:119.17167\tvalidation_1-rmse:119.00179\n",
      "[199]\tvalidation_0-rmse:119.17148\tvalidation_1-rmse:119.00159\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.32 seconds\n",
      "\n",
      "\n",
      "Simulation:  13\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:0.62131\tvalidation_1-rmse:0.63326\n",
      "[50]\tvalidation_0-rmse:0.62130\tvalidation_1-rmse:0.63325\n",
      "[100]\tvalidation_0-rmse:0.62129\tvalidation_1-rmse:0.63324\n",
      "[150]\tvalidation_0-rmse:0.62129\tvalidation_1-rmse:0.63323\n",
      "[199]\tvalidation_0-rmse:0.62128\tvalidation_1-rmse:0.63323\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.29 seconds\n",
      "\n",
      "\n",
      "Simulation:  14\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  20000\n",
      "[0]\tvalidation_0-rmse:15.56723\tvalidation_1-rmse:15.56549\n",
      "[50]\tvalidation_0-rmse:15.56726\tvalidation_1-rmse:15.56552\n",
      "[100]\tvalidation_0-rmse:15.56729\tvalidation_1-rmse:15.56555\n",
      "[150]\tvalidation_0-rmse:15.56732\tvalidation_1-rmse:15.56558\n",
      "[199]\tvalidation_0-rmse:15.56735\tvalidation_1-rmse:15.56561\n",
      "[INFO] Model trained\n",
      "[INFO] Time 15.59 seconds\n",
      "\n",
      "\n",
      "Simulation:  15\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  800\n",
      "[0]\tvalidation_0-rmse:2.42208\tvalidation_1-rmse:2.42017\n",
      "[50]\tvalidation_0-rmse:2.42175\tvalidation_1-rmse:2.41974\n",
      "[100]\tvalidation_0-rmse:2.42143\tvalidation_1-rmse:2.41931\n",
      "[150]\tvalidation_0-rmse:2.42110\tvalidation_1-rmse:2.41889\n",
      "[199]\tvalidation_0-rmse:2.42078\tvalidation_1-rmse:2.41847\n",
      "[INFO] Model trained\n",
      "[INFO] Time 1.32 seconds\n",
      "\n",
      "\n",
      "Simulation:  16\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  40000\n",
      "[0]\tvalidation_0-rmse:27.16590\tvalidation_1-rmse:27.11468\n",
      "[50]\tvalidation_0-rmse:27.16428\tvalidation_1-rmse:27.11314\n",
      "[100]\tvalidation_0-rmse:27.16266\tvalidation_1-rmse:27.11160\n",
      "[150]\tvalidation_0-rmse:27.16104\tvalidation_1-rmse:27.11007\n",
      "[199]\tvalidation_0-rmse:27.15947\tvalidation_1-rmse:27.10858\n",
      "[INFO] Model trained\n",
      "[INFO] Time 29.17 seconds\n",
      "\n",
      "\n",
      "Simulation:  17\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  20000\n",
      "[0]\tvalidation_0-rmse:1.65437\tvalidation_1-rmse:1.66580\n",
      "[50]\tvalidation_0-rmse:1.65421\tvalidation_1-rmse:1.66565\n",
      "[100]\tvalidation_0-rmse:1.65405\tvalidation_1-rmse:1.66550\n",
      "[150]\tvalidation_0-rmse:1.65390\tvalidation_1-rmse:1.66535\n",
      "[199]\tvalidation_0-rmse:1.65375\tvalidation_1-rmse:1.66521\n",
      "[INFO] Model trained\n",
      "[INFO] Time 15.11 seconds\n",
      "\n",
      "\n",
      "Simulation:  18\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  4000\n",
      "[0]\tvalidation_0-rmse:2.99437\tvalidation_1-rmse:3.01767\n",
      "[50]\tvalidation_0-rmse:2.99369\tvalidation_1-rmse:3.01702\n",
      "[100]\tvalidation_0-rmse:2.99302\tvalidation_1-rmse:3.01638\n",
      "[150]\tvalidation_0-rmse:2.99235\tvalidation_1-rmse:3.01574\n",
      "[199]\tvalidation_0-rmse:2.99169\tvalidation_1-rmse:3.01512\n",
      "[INFO] Model trained\n",
      "[INFO] Time 4.18 seconds\n",
      "\n",
      "\n",
      "Simulation:  19\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  800\n",
      "[0]\tvalidation_0-rmse:303.34831\tvalidation_1-rmse:291.37473\n",
      "[50]\tvalidation_0-rmse:303.34594\tvalidation_1-rmse:291.37257\n",
      "[100]\tvalidation_0-rmse:303.34359\tvalidation_1-rmse:291.37042\n",
      "[150]\tvalidation_0-rmse:303.34123\tvalidation_1-rmse:291.36826\n",
      "[199]\tvalidation_0-rmse:303.33893\tvalidation_1-rmse:291.36616\n",
      "[INFO] Model trained\n",
      "[INFO] Time 1.33 seconds\n",
      "\n",
      "\n",
      "Simulation:  20\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  20000\n",
      "[0]\tvalidation_0-rmse:43.79977\tvalidation_1-rmse:43.60885\n",
      "[50]\tvalidation_0-rmse:43.79376\tvalidation_1-rmse:43.60315\n",
      "[100]\tvalidation_0-rmse:43.78777\tvalidation_1-rmse:43.59748\n",
      "[150]\tvalidation_0-rmse:43.78180\tvalidation_1-rmse:43.59182\n",
      "[199]\tvalidation_0-rmse:43.77598\tvalidation_1-rmse:43.58631\n",
      "[INFO] Model trained\n",
      "[INFO] Time 13.33 seconds\n",
      "\n",
      "\n",
      "Simulation:  21\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:1.97106\tvalidation_1-rmse:2.00720\n",
      "[50]\tvalidation_0-rmse:1.97084\tvalidation_1-rmse:2.00693\n",
      "[100]\tvalidation_0-rmse:1.97062\tvalidation_1-rmse:2.00667\n",
      "[150]\tvalidation_0-rmse:1.97040\tvalidation_1-rmse:2.00640\n",
      "[199]\tvalidation_0-rmse:1.97019\tvalidation_1-rmse:2.00614\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.86 seconds\n",
      "\n",
      "\n",
      "Simulation:  22\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  20000\n",
      "[0]\tvalidation_0-rmse:3952.68026\tvalidation_1-rmse:887.82230\n",
      "[50]\tvalidation_0-rmse:3948.86462\tvalidation_1-rmse:884.18666\n",
      "[100]\tvalidation_0-rmse:3945.14361\tvalidation_1-rmse:880.84931\n",
      "[150]\tvalidation_0-rmse:3941.51681\tvalidation_1-rmse:877.81145\n",
      "[199]\tvalidation_0-rmse:3938.05348\tvalidation_1-rmse:875.12569\n",
      "[INFO] Model trained\n",
      "[INFO] Time 13.06 seconds\n",
      "\n",
      "\n",
      "Simulation:  23\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  2000\n",
      "[0]\tvalidation_0-rmse:45.33797\tvalidation_1-rmse:43.68055\n",
      "[50]\tvalidation_0-rmse:45.33803\tvalidation_1-rmse:43.68064\n",
      "[100]\tvalidation_0-rmse:45.33810\tvalidation_1-rmse:43.68074\n",
      "[150]\tvalidation_0-rmse:45.33816\tvalidation_1-rmse:43.68083\n",
      "[199]\tvalidation_0-rmse:45.33823\tvalidation_1-rmse:43.68092\n",
      "[INFO] Model trained\n",
      "[INFO] Time 2.56 seconds\n",
      "\n",
      "\n",
      "Simulation:  24\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  2000\n",
      "[0]\tvalidation_0-rmse:338.92514\tvalidation_1-rmse:200.74212\n",
      "[50]\tvalidation_0-rmse:338.92502\tvalidation_1-rmse:200.74205\n",
      "[100]\tvalidation_0-rmse:338.92491\tvalidation_1-rmse:200.74200\n",
      "[150]\tvalidation_0-rmse:338.92478\tvalidation_1-rmse:200.74193\n",
      "[199]\tvalidation_0-rmse:338.92466\tvalidation_1-rmse:200.74187\n",
      "[INFO] Model trained\n",
      "[INFO] Time 3.10 seconds\n",
      "\n",
      "\n",
      "Simulation:  25\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  4000\n",
      "[0]\tvalidation_0-rmse:37.58017\tvalidation_1-rmse:35.12897\n",
      "[50]\tvalidation_0-rmse:37.57983\tvalidation_1-rmse:35.12864\n",
      "[100]\tvalidation_0-rmse:37.57949\tvalidation_1-rmse:35.12831\n",
      "[150]\tvalidation_0-rmse:37.57915\tvalidation_1-rmse:35.12799\n",
      "[199]\tvalidation_0-rmse:37.57882\tvalidation_1-rmse:35.12767\n",
      "[INFO] Model trained\n",
      "[INFO] Time 5.15 seconds\n",
      "\n",
      "\n",
      "Simulation:  26\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  2000\n",
      "[0]\tvalidation_0-rmse:177.44306\tvalidation_1-rmse:171.31884\n",
      "[50]\tvalidation_0-rmse:177.44182\tvalidation_1-rmse:171.31751\n",
      "[100]\tvalidation_0-rmse:177.44058\tvalidation_1-rmse:171.31618\n",
      "[150]\tvalidation_0-rmse:177.43935\tvalidation_1-rmse:171.31486\n",
      "[199]\tvalidation_0-rmse:177.43814\tvalidation_1-rmse:171.31355\n",
      "[INFO] Model trained\n",
      "[INFO] Time 2.53 seconds\n",
      "\n",
      "\n",
      "Simulation:  27\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  40000\n",
      "[0]\tvalidation_0-rmse:5.32662\tvalidation_1-rmse:5.31234\n",
      "[50]\tvalidation_0-rmse:5.32575\tvalidation_1-rmse:5.31146\n",
      "[100]\tvalidation_0-rmse:5.32487\tvalidation_1-rmse:5.31058\n",
      "[150]\tvalidation_0-rmse:5.32400\tvalidation_1-rmse:5.30971\n",
      "[199]\tvalidation_0-rmse:5.32315\tvalidation_1-rmse:5.30886\n",
      "[INFO] Model trained\n",
      "[INFO] Time 31.86 seconds\n",
      "\n",
      "\n",
      "Simulation:  28\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  4000\n",
      "[0]\tvalidation_0-rmse:305.65847\tvalidation_1-rmse:261.19043\n",
      "[50]\tvalidation_0-rmse:304.60868\tvalidation_1-rmse:260.29695\n",
      "[100]\tvalidation_0-rmse:303.56520\tvalidation_1-rmse:259.40885\n",
      "[150]\tvalidation_0-rmse:302.52807\tvalidation_1-rmse:258.52616\n",
      "[199]\tvalidation_0-rmse:301.51782\tvalidation_1-rmse:257.66636\n",
      "[INFO] Model trained\n",
      "[INFO] Time 3.31 seconds\n",
      "\n",
      "\n",
      "Simulation:  29\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  40000\n",
      "[0]\tvalidation_0-rmse:658.33505\tvalidation_1-rmse:644.52395\n",
      "[50]\tvalidation_0-rmse:658.15990\tvalidation_1-rmse:644.34998\n",
      "[100]\tvalidation_0-rmse:657.98527\tvalidation_1-rmse:644.17652\n",
      "[150]\tvalidation_0-rmse:657.81109\tvalidation_1-rmse:644.00351\n",
      "[199]\tvalidation_0-rmse:657.64090\tvalidation_1-rmse:643.83447\n",
      "[INFO] Model trained\n",
      "[INFO] Time 28.53 seconds\n",
      "\n",
      "\n",
      "Simulation:  30\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  2000\n",
      "[0]\tvalidation_0-rmse:0.86936\tvalidation_1-rmse:0.86466\n",
      "[50]\tvalidation_0-rmse:0.86938\tvalidation_1-rmse:0.86469\n",
      "[100]\tvalidation_0-rmse:0.86941\tvalidation_1-rmse:0.86472\n",
      "[150]\tvalidation_0-rmse:0.86944\tvalidation_1-rmse:0.86475\n",
      "[199]\tvalidation_0-rmse:0.86947\tvalidation_1-rmse:0.86479\n",
      "[INFO] Model trained\n",
      "[INFO] Time 1.89 seconds\n",
      "\n",
      "\n",
      "Simulation:  31\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  8000\n",
      "[0]\tvalidation_0-rmse:27.59310\tvalidation_1-rmse:34.86083\n",
      "[50]\tvalidation_0-rmse:27.58116\tvalidation_1-rmse:34.83739\n",
      "[100]\tvalidation_0-rmse:27.56931\tvalidation_1-rmse:34.81411\n",
      "[150]\tvalidation_0-rmse:27.55754\tvalidation_1-rmse:34.79095\n",
      "[199]\tvalidation_0-rmse:27.54606\tvalidation_1-rmse:34.76834\n",
      "[INFO] Model trained\n",
      "[INFO] Time 6.59 seconds\n",
      "\n",
      "\n",
      "Simulation:  32\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  800\n",
      "[0]\tvalidation_0-rmse:15.04060\tvalidation_1-rmse:15.00271\n",
      "[50]\tvalidation_0-rmse:15.04078\tvalidation_1-rmse:15.00290\n",
      "[100]\tvalidation_0-rmse:15.04097\tvalidation_1-rmse:15.00308\n",
      "[150]\tvalidation_0-rmse:15.04115\tvalidation_1-rmse:15.00326\n",
      "[199]\tvalidation_0-rmse:15.04134\tvalidation_1-rmse:15.00344\n",
      "[INFO] Model trained\n",
      "[INFO] Time 1.34 seconds\n",
      "\n",
      "\n",
      "Simulation:  33\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  800\n",
      "[0]\tvalidation_0-rmse:282.08115\tvalidation_1-rmse:283.11714\n",
      "[50]\tvalidation_0-rmse:282.07555\tvalidation_1-rmse:283.11129\n",
      "[100]\tvalidation_0-rmse:282.06995\tvalidation_1-rmse:283.10545\n",
      "[150]\tvalidation_0-rmse:282.06436\tvalidation_1-rmse:283.09961\n",
      "[199]\tvalidation_0-rmse:282.05891\tvalidation_1-rmse:283.09391\n",
      "[INFO] Model trained\n",
      "[INFO] Time 1.53 seconds\n",
      "\n",
      "\n",
      "Simulation:  34\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  40000\n",
      "[0]\tvalidation_0-rmse:278.20851\tvalidation_1-rmse:269.99768\n",
      "[50]\tvalidation_0-rmse:278.20438\tvalidation_1-rmse:269.99329\n",
      "[100]\tvalidation_0-rmse:278.20027\tvalidation_1-rmse:269.98893\n",
      "[150]\tvalidation_0-rmse:278.19616\tvalidation_1-rmse:269.98457\n",
      "[199]\tvalidation_0-rmse:278.19215\tvalidation_1-rmse:269.98032\n",
      "[INFO] Model trained\n",
      "[INFO] Time 28.52 seconds\n",
      "\n",
      "\n",
      "Simulation:  35\n",
      "[INFO] Dataset imported\n",
      "[INFO] Number of training instances:  4000\n",
      "[0]\tvalidation_0-rmse:18.56223\tvalidation_1-rmse:19.55709\n",
      "[50]\tvalidation_0-rmse:18.55754\tvalidation_1-rmse:19.55154\n",
      "[100]\tvalidation_0-rmse:18.55287\tvalidation_1-rmse:19.54600\n",
      "[150]\tvalidation_0-rmse:18.54822\tvalidation_1-rmse:19.54048\n",
      "[199]\tvalidation_0-rmse:18.54367\tvalidation_1-rmse:19.53509\n",
      "[INFO] Model trained\n",
      "[INFO] Time 3.41 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {'ATE': [], 'Error_ATE': [], 'Error_PEHE':[]} \n",
    "for idx in range(DataLoader.nProblems):\n",
    "\n",
    "    # Start timer\n",
    "    #\n",
    "    start1 = time.time()\n",
    "    \n",
    "    \n",
    "    # Load training data\n",
    "    trainX, trainT, trainY, train_potential_Y = DataLoader.getTraining( idx )\n",
    "\n",
    "    # Load testing data\n",
    "    testX, testT, testY, test_potential_Y  = DataLoader.getTesting( idx )\n",
    "    #\n",
    "    print('Simulation: ', idx)\n",
    "    print('[INFO] Dataset imported')\n",
    "    print('[INFO] Number of training instances: ', trainX.shape[0])\n",
    "    \n",
    " \n",
    "    # Setup scaler for inputs\n",
    "    #\n",
    "    scalerX = RobustScaler()\n",
    "    trainX  = scalerX.fit_transform( trainX )\n",
    "    testX   = scalerX.transform( testX )\n",
    "\n",
    "\n",
    "    tt = np.array([[1,0] if x == 0 else [0,1] for x in trainT]).flatten()\n",
    "\n",
    "    def custom_loss(y_true:np.ndarray=None, y_pred:np.ndarray=None)->(np.ndarray,np.ndarray):\n",
    "        grad = 2*(y_pred.flatten() - y_true.flatten()) * tt\n",
    "        hess = (0*y_pred.flatten() + 2)  * tt\n",
    "\n",
    "        return grad, hess\n",
    "    \n",
    "\n",
    "\n",
    "    # Setup XGBoost\n",
    "    #\n",
    "    # import xgboost\n",
    "    # model = xgboost.XGBRegressor(n_estimators=200, \n",
    "    #                              max_depth=4, \n",
    "    #                              objective=custom_loss, \n",
    "    #                              learning_rate=1e-2, \n",
    "    #                             #  booster=\"gblinear\",\n",
    "    #                              n_jobs=-1,\n",
    "    #                              tree_method=\"hist\", \n",
    "    #                              multi_strategy=\"multi_output_tree\")\n",
    "    import xgboost\n",
    "    model = xgboost.XGBRegressor(n_estimators=200, \n",
    "                                 max_depth=5, \n",
    "                                 objective=custom_loss, \n",
    "                                 learning_rate=5e-5, \n",
    "                                #  booster=\"gblinear\",\n",
    "                                 #\n",
    "                                 reg_alpha = 0,\n",
    "                                 reg_lambda = 1.0,\n",
    "                                 gamma = 1.0,\n",
    "                                 min_child_weight = 2.0,\n",
    "                                 max_leaves = 2,\n",
    "                                 #\n",
    "                                 n_jobs=-1,\n",
    "                                 tree_method=\"hist\", \n",
    "                                 multi_strategy=\"multi_output_tree\")\n",
    "    \n",
    "    # Create outputs for DragonNet (concatenate Y & T)\n",
    "    #\n",
    "    if \"ACIC\" in problem:\n",
    "        scalerY       = RobustScaler()\n",
    "        trainY_scaled = scalerY.fit_transform( trainY.reshape(-1,1) ).squeeze(-1)      \n",
    "        yt_train = np.concatenate([trainY_scaled.reshape(-1,1), trainT.reshape(-1,1)], axis = 1)\n",
    "    else:\n",
    "        yt_train = np.concatenate([trainY.reshape(-1,1), trainT.reshape(-1,1)], axis = 1)\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    #\n",
    "    # model.fit(trainX, yt_train);\n",
    "    model.fit(trainX, yt_train, eval_set=[(trainX, train_potential_Y), (testX, test_potential_Y)], verbose=50);\n",
    "    print('[INFO] Model trained')    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #\n",
    "    #\n",
    "    # *** Predictions ***\n",
    "    #\n",
    "    #       \n",
    "\n",
    "    # Get predictions\n",
    "    #\n",
    "    test_y_hat = model.predict( testX )\n",
    "\n",
    "    if \"ACIC\" in problem:\n",
    "        test_y_hat[:,0] = scalerY.inverse_transform( test_y_hat[:,0].reshape(-1,1) ).squeeze()\n",
    "        test_y_hat[:,1] = scalerY.inverse_transform( test_y_hat[:,1].reshape(-1,1) ).squeeze()    \n",
    "    \n",
    "    # ATE\n",
    "    #\n",
    "    real_ATE = ( test_potential_Y[:,1] - test_potential_Y[:,0] ).mean()\n",
    "    \n",
    "    \n",
    "    # Error PEHE\n",
    "    #\n",
    "    Error_PEHE = PEHE(test_potential_Y, test_y_hat)\n",
    "    \n",
    "    \n",
    "    # Error ATE\n",
    "    #\n",
    "    Error_ATE = ATE(test_potential_Y, test_y_hat)  \n",
    "    \n",
    "        \n",
    "    # Store errors of PEHE and ATE\n",
    "    #\n",
    "    results['ATE']            += [ np.round(real_ATE,   6) ]\n",
    "    results['Error_ATE']      += [ np.round(Error_ATE,  6) ]\n",
    "    results['Error_PEHE']     += [ np.round(Error_PEHE, 6) ]\n",
    "    print('[INFO] Time %.2f seconds\\n\\n' % (time.time() - start1))\n",
    "\n",
    "    # from sklearn import metrics\n",
    "    # print('0: ', metrics.mean_absolute_error(test_potential_Y[:,0], test_y_hat[:,0]))\n",
    "    # print('1: ', metrics.mean_absolute_error(test_potential_Y[:,1], test_y_hat[:,1]))    \n",
    "\n",
    "\n",
    "    \n",
    "    # Save results (at each iteration)\n",
    "    df = pd.DataFrame( results )\n",
    "    df['Problem'] = [f\"{problem} {x}\" for x in df.index]\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    # print(results['Error_ATE'])\n",
    "    # print(results['Error_PEHE'])\n",
    "    # print(50*\"-\" + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
